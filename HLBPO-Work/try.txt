function [Leader_score, Leader_pos, Convergence_curve] = HLBPO(SearchAgents_no, areas, parties, lambda_max, Max_iter, plr, glr, dim, fobj)
    % Initialization
    Positions = initialization(SearchAgents_no, dim);
    Convergence_curve = zeros(1, Max_iter);
    
    % Election
    for t = 1:Max_iter
        % Store previous population and fitness
        P_prev = Positions;
        fitness_prev = fobj(P_prev);
        
        % Election campaign
        for p = 1:parties
            for j = 1:areas
                for k = 1:dim
                    Positions(p, j, k) = ElectionCampaign(Positions(p, j, k), P_prev(p, j, k), Leader_pos, Convergence_curve);
                end
            end
        end
        
        % Party Switching
        PartySwitching(Positions, lambda_max);
        
        % Election
        Election(Positions, fobj);
        
        % Parliamentary Affairs
        % (This phase is not explicitly implemented here as it involves updating members based on other randomly selected members)
        
        % Hyper Learning Position Updating Strategy
        lambda = lambda_max - lambda_max * t / Max_iter;
        Positions = HyperLearningPositionUpdating(Positions, plr, glr);
        
        % Store convergence curve data
        Convergence_curve(t) = min(fobj(Positions(:)));
    end
    
    % Final results
    Leader_score = min(fobj(Positions(:)));
    [~, idx] = min(fobj(Positions(:)));
    Leader_pos = Positions(idx);
end

function Positions = initialization(SearchAgents_no, dim)
    Positions = rand(SearchAgents_no, dim) > 0.5;
end

function new_pos = ElectionCampaign(pos, prev_pos, Leader_pos, Convergence_curve)
    % Your implementation of election campaign logic here
    new_pos = pos; % Placeholder logic
end

function PartySwitching(Positions, lambda_max)
    [parties, areas, dim] = size(Positions);
    
    psr = (1 - lambda_max / Max_iter) * lambda_max;
    
    for p = 1:parties
        for j = 1:areas
            if rand() < psr
                % Selecting a party other than current to send the member
                toParty = randi(parties);
                while toParty == p
                    toParty = randi(parties);
                end
                
                % Selecting a least fit member in the destination party
                [~, least_fit_index] = max(fitness(toParty, :));
                
                % Switching members between parties
                temp = Positions(p, j, :);
                Positions(p, j, :) = Positions(toParty, least_fit_index, :);
                Positions(toParty, least_fit_index, :) = temp;
            end
        end
    end
end



function Election(Positions, fobj)
    % Calculate fitness of each member
    fitness = fobj(Positions);
    
    % Find party leaders (fittest member of each party)
    [~, leader_indices] = min(fitness, [], 2);
    Leader_pos = zeros(size(Positions));
    for i = 1:size(Positions, 1)
        Leader_pos(i, :, :) = Positions(i, leader_indices(i), :);
    end
    
    % Find constituency winners (fittest member of each constituency)
    [~, constituency_winners] = min(fitness, [], 3);
    
    % Store the position and fitness of global best solution
    global Best_pos Best_score
    [min_fitness, min_index] = min(fitness(:));
    if min_fitness < Best_score
        Best_score = min_fitness;
        Best_pos = Positions(min_index);
    end
end


function Positions = HyperLearningPositionUpdating(Positions, plr, glr, personal_best_positions, global_best_position)
    [~, parties, areas, dim] = size(Positions);
    
    for p = 1:parties
        for j = 1:areas
            for k = 1:dim
                TF = TransferFunction(Positions(p, j, k));
                r1 = rand();
                
                if r1 < plr
                    % Update position using Eq. (14)
                    if rand() < TF
                        Positions(p, j, k) = 1 - Positions(p, j, k);
                    end
                elseif r1 < glr
                    % Update position with respect to personal best solution
                    Positions(p, j, k) = UpdatePosition(Positions(p, j, k), personal_best_positions(p, k));
                else
                    % Update position with respect to global best solution
                    Positions(p, j, k) = UpdatePosition(Positions(p, j, k), global_best_position(k));
                end
            end
        end
    end
end

function updated_position = UpdatePosition(current_position, reference_position)
    r2 = rand();
    if r2 < 0.5
        updated_position = current_position;
    else
        updated_position = reference_position;
    end
end

function TF = TransferFunction(x)
    TF = abs(x) / sqrt(x^2 + 1);
end

