
function [Best_score, Best_pos, cg_curve] = HLBPO(populationSize, parties, areas, lambda, Max_iteration, pl, gl, X, Y, O)
    % BPO: Binary Political Optimizer algorithm
    % Inputs:
    %   - populationSize: Number of search agents
    %   - areas: Number of areas/constituencies
    %   - parties: Number of political parties
    %   - lambda: Maximum party switching rate
    %   - Max_iteration: Maximum number of iterations
    %   - pl: Personal learning rate
    %   - gl: Global learning rate
    %   - Y: Labels
    %   - O: Other parameters (e.g., cross-validation settings)
    % Outputs:
    %   - Best_score: Best fitness score found by the algorithm
    %   - Best_pos: Best position (selected features)
    %   - cg_curve: Cost (fitness) curve over iterations
    
    % Initialization
    dim = size(X, 2); % Dimensionality of the problem (number of features)
    Positions = initialization(populationSize, dim); % Initialize positions randomly
    
    % Initialize other variables
    cg_curve = zeros(1, Max_iteration);
    Best_score = inf;
    Best_pos = zeros(1, dim);
    
    partyleader = zeros(1, parties);
    constituencywinners  = zeros(1, areas);
    
    % Main loop
    for iter = 1:Max_iteration

        % Evaluate fitness for each candidate solution in each area
        costs = zeros(1, populationSize);

        % Election
        for i = 1:populationSize
            costs(i) = jFitnessFunction(X,Y,Positions(i, :), O);
        end
        
        % Update global best position and score
        [cg_curve(iter), best_idx] = min(costs);


        if cg_curve(iter) < Best_score
            Best_score = cg_curve(iter);
            Best_pos = Positions(best_idx, :);
        end
        
        % Update positions
        new_positions = zeros(populationSize, dim);
        for i = 1:populationSize
            r = rand();
            if r <= pl
                % Personal learning
                new_positions(i, :) = PersonalLearning(Positions(i, :), best_idx, gl);
            elseif r <= pl + gl
                % Global learning
                new_positions(i, :) = GlobalLearning(Positions(i, :), best_idx, Positions, costs);
            else
                % Party switching
                new_positions(i, :) = PartySwitching(Positions(i, :), areas, parties, lambda);
            end
        end
        Positions = new_positions;
    end
end

function new_position = PersonalLearning(position, best_idx, gl)
    % Personal learning phase
    new_position = position;
    new_position(best_idx) = ~new_position(best_idx); % Flip the bit of the best feature
end

function new_position = GlobalLearning(position, best_idx, Positions, costs)
    % Global learning phase
    [~, best_neighbor] = min(costs);
    if best_neighbor ~= best_idx
        new_position = Positions(best_neighbor, :);
    else
        new_position = position;
    end
end

function new_position = PartySwitching(position, areas, parties, lambda)
    % Party switching phase
    r = rand();
    if r <= lambda
        % Switch with the least fit member of a randomly selected party
        party_to_switch = randi(parties);
        least_fit_idx = Inf;
        least_fit_cost = Inf;
        for i = 1:areas
            candidate_idx = (party_to_switch - 1) * areas + i;
            if costs(candidate_idx) < least_fit_cost
                least_fit_idx = candidate_idx;
                least_fit_cost = costs(candidate_idx);
            end
        end
        new_position = position;
        new_position(least_fit_idx) = ~new_position(least_fit_idx); % Switch the least fit member
    else
        new_position = position;
    end
end
